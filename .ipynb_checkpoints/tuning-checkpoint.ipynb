{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "underfitting\n",
    "    over simplyfying\n",
    "    examples:\n",
    "        error due to bias - does not do well in training set\n",
    "        \n",
    "overfitting\n",
    "    over estimating\n",
    "    examples\n",
    "        error due to variance - does well in training set but just memorizes instead of learning characteristics\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cross validation\n",
    "    this is another subset of data neither in testing or training. This is used to make decisions on the models and parameters\n",
    "k fold cross validation\n",
    "     creating multiple subsets and then training and testing on different ones k times\n",
    "     \n",
    "     from sklearn.model_selection import KFold\n",
    "     kf=KFold(12,3, shuffle=True)\n",
    "     for train_indices, test_indices in kf:\n",
    "         print (train_indicies,test_indices)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learning curve\n",
    "    increasing points in cross validation means training error will increase and cross validation error will decrease\n",
    "    eventually they will converge on errors but the errors will converge at a lower point on a good fit vs an underfit\n",
    "    \n",
    "    Underfit\n",
    "        will converge but at a high eror\n",
    "    overfit\n",
    "        will never have cross validation error and training error converge"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scoreslearning_curve(estimator, X, y, cv=None, n_jobs=1, train_sizes=np.linspace(.1,1.0,num_trainings))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parameters\n",
    "    estimator - clasifier\n",
    "    train_sizes- sizes of the chunks of data used to draw each point in the curve\n",
    "    train_scores - training scores for algorithm trained\n",
    "    test_scores - test scores for algorithm trained\n",
    "    \n",
    "observations\n",
    "    training and test come as a list of 3 as function is 3 fold validation\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hyper parameters\n",
    "    example \n",
    "        decision trees - depth\n",
    "            parameter leaf\n",
    "        SVM\n",
    "            kernel - small linear or polynomial\n",
    "            C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline\n",
    "\n",
    "# produces a plots of all features against eachother\n",
    "sns.pairplot(diabetes, hue='Outcome')\n",
    "\n",
    "# produces correlation map\n",
    "sns.heatmap(diabetes.corr(), annot=True, cmap=\"YlGnBu\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-2032539ef1f5>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-2032539ef1f5>\"\u001b[1;36m, line \u001b[1;32m21\u001b[0m\n\u001b[1;33m    suppor vector builder\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Random forest param builder\n",
    "clf_rf = RandomForestClassifier()\n",
    "\n",
    "# Set up the hyperparameter search\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"n_estimators\": list(range(10, 200)),\n",
    "              \"max_features\": list(range(1, X_test.shape[1]+1)),\n",
    "              \"min_samples_split\": list(range(2, 11)),\n",
    "              \"min_samples_leaf\": list(range(1, 11)),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "# adaboost param builder\n",
    "param_ada={'n_estimators':[1,10,20,30,40,50,60, 200, 400], 'learning_rate':[0.001, 0.2,0.4,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.2]}\n",
    "# Run a randomized search over the hyperparameters\n",
    "clf_ada=AdaB()\n",
    "random_ada=RandomizedSearchCV(clf_ada, param_distributions=param_ada)\n",
    "\n",
    "\n",
    "suppor vector builder\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# Set up the hyperparameter search\n",
    "# look at setting up your search for C (recommend 0-10 range), \n",
    "# kernel, and degree\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "# \"C\": [0.1, 0.5, 1, 3, 5],\n",
    "#               \"kernel\": ['linear','rbf']\n",
    "params_svc={'C': list(range(1,6)), 'kernel':['linear', 'rbf'], 'degree':list(range(4))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We tried to predict diabetes in 768 patients. Reviewing the data there was no missing data and there was a low prevalence of diabetes at 34.8%.\n",
    "\n",
    "out of Random Forests, SVM and Adaboost classifiers, ADA boost gave us the best score\n",
    "\n",
    "Accuracy score for adaboost : 0.7662337662337663\n",
    "Precision score adaboost : 0.6666666666666666\n",
    "Recall score adaboost : 0.6909090909090909\n",
    "F1 score adaboost : 0.6785714285714286\n",
    "\n",
    "\n",
    "Based on the correlation heatmap I was able to tell that Glucose, BMI, and AGE were all important in the predictions. This was confirmed by plotting the feature importance after completing the predictions and fit\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
