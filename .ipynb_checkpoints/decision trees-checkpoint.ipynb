{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Entropy\n",
    "    entropy is the degree of randomness\n",
    "   \n",
    "   from math import log\n",
    "    \n",
    "    entropy= -(m/m+n)log(m/m+n,2)+(-(n/m+n)log(n/m+n,2))\n",
    "    or=-p1log(p1,2)+(-p2log(p2,2))\n",
    "    entropy is degree of randomness\n",
    "    \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4150374992788438"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "-log(0.75,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863120568566631"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-4/14*log((4/14),2))+(-10/14*log(10/14,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(m,n,q=0):\n",
    "    tot=m+n+q\n",
    "    p1=m/tot\n",
    "    p2=n/tot\n",
    "    p3=q/tot\n",
    "    if p3!=0:\n",
    "        ans=-p1*log(p1,2)-p2*log(p2,2)-p3*log(p3,2)\n",
    "    else:\n",
    "        ans=-p1*log(p1,2)-p2*log(p2,2)\n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3346791410515946"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(8,3,2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "information gain=parent entropy- weighted average of children entropy\n",
    "    weighted average of children entropy where \n",
    "        n1=total subjects in leaf 1\n",
    "        n2=total subjects in leaf 2\n",
    "        N=total subjects in Parent node\n",
    "        x1=total subjects of x paramater leaf 1\n",
    "        x2= total subjects of x parameter leaf 2\n",
    "        y1=total subjects of y paramater leaf 1\n",
    "        y2=total subjects of y paramater leaf 2\n",
    "        \n",
    "        entropyleaf1=-(x1/n1*np.log2(x1/n1)+y1/n1*np.log2(y1/n1)\n",
    "        entropyleaf2=-(x2/n2*np.log2(x2/n2)+y2/n2*np.log2(y2/n2)\n",
    "        weighted_average of entropy=n1/N*entropyleaf1+n2/N*entropyleaf2\n",
    "\n",
    "decision trees will use information gain to decide which node to choose\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def two_group_ent(first, tot):                        \n",
    "    return -(first/tot*np.log2(first/tot) +           \n",
    "             (tot-first)/tot*np.log2((tot-first)/tot))\n",
    "\n",
    "tot_ent = two_group_ent(10, 24)                       \n",
    "g17_ent = 15/24 * two_group_ent(11,15) +9/24 * two_group_ent(6,9)                  \n",
    "\n",
    "answer = tot_ent - g17_ent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11260735516748976"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672614014836633"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g17_ent=15/24*test(11,4)+9/24*test(6,3)\n",
    "g17_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798687566511527"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_ent=test(10,14)\n",
    "parent_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parent_ent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b7aa00447c48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparent_ent\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mg17_ent\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'parent_ent' is not defined"
     ]
    }
   ],
   "source": [
    "parent_ent-g17_ent"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "hyperparameters - parameters of a decision tree\n",
    "    depth=largest length between leaf and root\n",
    "    amount of leaves is 2**depth\n",
    "    Min_sample_split - minimum amount of samples to split - will stop leaf/decision at this point\n",
    "    min_sample_leaf - minimum amount of samples allowing to be in each leaf after split\n",
    "        this is good to set as it would be a waste of resources if you only split a leaf to only one sample with no gain of knowledge\n",
    "    Overfitting causes - \n",
    "        small samples per split/leaf\n",
    "    underfitting causes\n",
    "        small depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Store the 'Survived' feature in a new variable and remove it from the dataset\n",
    "outcomes = full_data['Survived']\n",
    "features_raw = full_data.drop('Survived', axis = 1)\n",
    "\n",
    "# Show the new dataset with 'Survived' removed\n",
    "display(features_raw.head())\n",
    "# Removing the names\n",
    "features_no_names = features_raw.drop(['Name'], axis=1)\n",
    "\n",
    "features = features.fillna(0.0)\n",
    "display(features.head())\n",
    "# One-hot encoding\n",
    "features = pd.get_dummies(features_no_names)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, outcomes, test_size=0.2, random_state=42)\n",
    "# Import the classifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "\n",
    "# TODO: Define the classifier, and fit it to the data\n",
    "model = DTC().fit(X_train,y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print('The training accuracy is', train_accuracy)\n",
    "print('The test accuracy is', test_accuracy)\n",
    "from sklearn.model_selection import GridSearchCV as GSCV\n",
    "\n",
    "# TODO: Train the model\n",
    "model2=DTC()\n",
    "parameters=[{'max_depth':[2,4,6,8,10], 'min_samples_split':[2,4,6,8], 'min_samples_leaf':[2,4,6,8,10]} ]\n",
    "clf=GSCV(model2, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "# TODO: Make predictions\n",
    "y_test_pred=clf.predict(X_test)\n",
    "\n",
    "# TODO: Calculate the accuracy\n",
    "test_accuracy=accuracy_score(y_test, y_test_pred)\n",
    "print('The best accuracy is '+str(test_accuracy)+' with the params '+str(clf.best_params_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
