{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Classification \n",
    "    Yes or No\n",
    "    perceptron algorithm - basis for neural network\n",
    "        boundary line - \n",
    "            w1x1+w2x2+b=0\n",
    "            Wx+b=0\n",
    "            W=(w1,w2) x=(x1,x2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(i,j):\n",
    "    \n",
    "    x=1.5*i+j-18\n",
    "    return x\n",
    "test(7,6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "perceptron \n",
    "    encoding of equation into a small graph\n",
    "    graph legend - \n",
    "        input nodes are the features, numbers going into the nodes are the feature coefficients\n",
    "        last input node is bias\n",
    "        \n",
    "        main nodes - equation or function node and step function node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Perceptron algorithm Line Trick\n",
    "    say random line w1x1+w2x2-10=0\n",
    "    then take point that is misclassified (xhat,yhat)\n",
    "    take @learning rate (.01 )\n",
    "    trick\n",
    "        w1-x1@=w1hat\n",
    "        w2-x2@=w2hat\n",
    "        1@=bhat\n",
    "    when prediction is 0 then add trick when prediction is 1 subtract trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(3*x1+4*x2-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(x1,x2,a):\n",
    "    w1=3\n",
    "    w2=4\n",
    "    b=-10\n",
    "    tot=w1+w2+b\n",
    "    cnt=0\n",
    "    while tot<0.0:\n",
    "        \n",
    "        w1=a*x1+w1\n",
    "        w2=a*x2+w2\n",
    "        b=a+b\n",
    "        tot=w1+w2+b\n",
    "        cnt+=1\n",
    "    return cnt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(1,1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    # Fill in code\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        yhat=prediction(X[i],W,b)\n",
    "        if yhat-y[i]==1:\n",
    "            W[0]-=X[i][0]*learn_rate\n",
    "            W[1]-=X[i][1]*learn_rate\n",
    "            b-=learn_rate\n",
    "        elif yhat-y[i]==-1:\n",
    "            W[0]+=X[i][0]*learn_rate\n",
    "            W[1]+=X[i][1]*learn_rate\n",
    "            b+=learn_rate\n",
    "\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
